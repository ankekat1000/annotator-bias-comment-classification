{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply BERT and 20-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8545,
     "status": "ok",
     "timestamp": 1729085791581,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "kP7sQ_0tdPkB",
    "outputId": "560f7a4c-ec8d-4fb9-dab2-979278dfb01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "We will use the GPU: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12102,
     "status": "ok",
     "timestamp": 1729085803679,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "HISYrQjzdRZd",
    "outputId": "f7b59906-3ac4-4909-be9c-68e5edb7861b"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Readand prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "executionInfo": {
     "elapsed": 22086,
     "status": "ok",
     "timestamp": 1729085898371,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "sQYHN6-TdHYW",
    "outputId": "9816ed23-c39f-410d-f7a3-e267f2ccde52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_beitrag (mb)</th>\n",
       "      <th>id_mb</th>\n",
       "      <th>komm_id (mf)</th>\n",
       "      <th>id_mf</th>\n",
       "      <th>Kommentar_id_rtl</th>\n",
       "      <th>id_rtl</th>\n",
       "      <th>comment_id_zon</th>\n",
       "      <th>id_zon</th>\n",
       "      <th>id_crowd</th>\n",
       "      <th>c_text</th>\n",
       "      <th>...</th>\n",
       "      <th>Tatsache_total</th>\n",
       "      <th>unangemessen_total_median</th>\n",
       "      <th>unangemessen_edulow_median</th>\n",
       "      <th>unangemessen_edumed_median</th>\n",
       "      <th>unangemessen_eduhigh_median</th>\n",
       "      <th>bereichernd_total_median</th>\n",
       "      <th>bereichernd_edulow_median</th>\n",
       "      <th>bereichernd_edumed_median</th>\n",
       "      <th>bereichernd_eduhigh_median</th>\n",
       "      <th>Tatsache_total_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>831.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Tolle Idee. Ich denke, dass dieses Projekt Tei...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Wohnungstausch sollte auch in belegungsgebunde...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>843.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Lebensbedingungen vor Ort könnten sogar geziel...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Super Ideen, da kommt Freude auf mitzumachen! ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>852.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Wenn der Staat schon Steuermittel ausgeben wil...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_beitrag (mb)  id_mb  komm_id (mf)  id_mf Kommentar_id_rtl  id_rtl  \\\n",
       "0            831.0    1.0           NaN    NaN              NaN     NaN   \n",
       "1            841.0    3.0           NaN    NaN              NaN     NaN   \n",
       "2            843.0    4.0           NaN    NaN              NaN     NaN   \n",
       "3            850.0    5.0           NaN    NaN              NaN     NaN   \n",
       "4            852.0    6.0           NaN    NaN              NaN     NaN   \n",
       "\n",
       "   comment_id_zon  id_zon  id_crowd  \\\n",
       "0             NaN     NaN         1   \n",
       "1             NaN     NaN         2   \n",
       "2             NaN     NaN         3   \n",
       "3             NaN     NaN         4   \n",
       "4             NaN     NaN         5   \n",
       "\n",
       "                                              c_text  ... Tatsache_total  \\\n",
       "0  Tolle Idee. Ich denke, dass dieses Projekt Tei...  ...       0.111111   \n",
       "1  Wohnungstausch sollte auch in belegungsgebunde...  ...       0.111111   \n",
       "2  Lebensbedingungen vor Ort könnten sogar geziel...  ...       0.333333   \n",
       "3  Super Ideen, da kommt Freude auf mitzumachen! ...  ...       0.111111   \n",
       "4  Wenn der Staat schon Steuermittel ausgeben wil...  ...       0.777778   \n",
       "\n",
       "   unangemessen_total_median  unangemessen_edulow_median  \\\n",
       "0                          0                           0   \n",
       "1                          0                           0   \n",
       "2                          0                           0   \n",
       "3                          0                           0   \n",
       "4                          0                           0   \n",
       "\n",
       "   unangemessen_edumed_median  unangemessen_eduhigh_median  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   bereichernd_total_median  bereichernd_edulow_median  \\\n",
       "0                         1                          1   \n",
       "1                         1                          0   \n",
       "2                         1                          1   \n",
       "3                         1                          1   \n",
       "4                         1                          1   \n",
       "\n",
       "   bereichernd_edumed_median  bereichernd_eduhigh_median  \\\n",
       "0                          1                           1   \n",
       "1                          1                           0   \n",
       "2                          1                           1   \n",
       "3                          1                           1   \n",
       "4                          1                           1   \n",
       "\n",
       "   Tatsache_total_median  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      1  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Crowdanno_Datenbereinigung_done.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729085898371,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "88UZX_5kee8z",
    "outputId": "b25032e9-5073-4b6e-eda4-f32d331be89a"
   },
   "outputs": [],
   "source": [
    "#list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N3ieRNae_Mnp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bereichernd_mixed_median\n",
       "0.0    7117\n",
       "1.0    6560\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get median/majorty vote for class Mixed\n",
    "df[\"bereichernd_mixed_median\"] = df[['bereichernd_1', \"bereichernd_4\", \"bereichernd_7\"]].median(axis=1)\n",
    "df[\"bereichernd_mixed_median\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bereichernd_mixed_median'] = df.bereichernd_mixed_median.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bereichernd_mixed_median\n",
       "0    7117\n",
       "1    6560\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"bereichernd_mixed_median\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729085898371,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "s6bj9m2af9la",
    "outputId": "5adb3666-599e-4905-98a6-10603c26e859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13677, 68)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729085898371,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "1Cm905fwgDfR"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=\"c_text\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729085898371,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "F0afCysAgKzf",
    "outputId": "144fb547-50f3-4f3c-808a-6da86d5e0c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13674"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_beitrag (mb)</th>\n",
       "      <th>id_mb</th>\n",
       "      <th>komm_id (mf)</th>\n",
       "      <th>id_mf</th>\n",
       "      <th>Kommentar_id_rtl</th>\n",
       "      <th>id_rtl</th>\n",
       "      <th>comment_id_zon</th>\n",
       "      <th>id_zon</th>\n",
       "      <th>id_crowd</th>\n",
       "      <th>c_text</th>\n",
       "      <th>...</th>\n",
       "      <th>unangemessen_total_median</th>\n",
       "      <th>unangemessen_edulow_median</th>\n",
       "      <th>unangemessen_edumed_median</th>\n",
       "      <th>unangemessen_eduhigh_median</th>\n",
       "      <th>bereichernd_total_median</th>\n",
       "      <th>bereichernd_edulow_median</th>\n",
       "      <th>bereichernd_edumed_median</th>\n",
       "      <th>bereichernd_eduhigh_median</th>\n",
       "      <th>Tatsache_total_median</th>\n",
       "      <th>bereichernd_mixed_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>831.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Tolle Idee. Ich denke, dass dieses Projekt Tei...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>841.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Wohnungstausch sollte auch in belegungsgebunde...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>843.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Lebensbedingungen vor Ort könnten sogar geziel...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Super Ideen, da kommt Freude auf mitzumachen! ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>852.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>Wenn der Staat schon Steuermittel ausgeben wil...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_beitrag (mb)  id_mb  komm_id (mf)  id_mf Kommentar_id_rtl  id_rtl  \\\n",
       "0            831.0    1.0           NaN    NaN              NaN     NaN   \n",
       "1            841.0    3.0           NaN    NaN              NaN     NaN   \n",
       "2            843.0    4.0           NaN    NaN              NaN     NaN   \n",
       "3            850.0    5.0           NaN    NaN              NaN     NaN   \n",
       "4            852.0    6.0           NaN    NaN              NaN     NaN   \n",
       "\n",
       "   comment_id_zon  id_zon  id_crowd  \\\n",
       "0             NaN     NaN         1   \n",
       "1             NaN     NaN         2   \n",
       "2             NaN     NaN         3   \n",
       "3             NaN     NaN         4   \n",
       "4             NaN     NaN         5   \n",
       "\n",
       "                                              c_text  ...  \\\n",
       "0  Tolle Idee. Ich denke, dass dieses Projekt Tei...  ...   \n",
       "1  Wohnungstausch sollte auch in belegungsgebunde...  ...   \n",
       "2  Lebensbedingungen vor Ort könnten sogar geziel...  ...   \n",
       "3  Super Ideen, da kommt Freude auf mitzumachen! ...  ...   \n",
       "4  Wenn der Staat schon Steuermittel ausgeben wil...  ...   \n",
       "\n",
       "  unangemessen_total_median  unangemessen_edulow_median  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "\n",
       "   unangemessen_edumed_median  unangemessen_eduhigh_median  \\\n",
       "0                           0                            0   \n",
       "1                           0                            0   \n",
       "2                           0                            0   \n",
       "3                           0                            0   \n",
       "4                           0                            0   \n",
       "\n",
       "   bereichernd_total_median  bereichernd_edulow_median  \\\n",
       "0                         1                          1   \n",
       "1                         1                          0   \n",
       "2                         1                          1   \n",
       "3                         1                          1   \n",
       "4                         1                          1   \n",
       "\n",
       "   bereichernd_edumed_median  bereichernd_eduhigh_median  \\\n",
       "0                          1                           1   \n",
       "1                          1                           0   \n",
       "2                          1                           1   \n",
       "3                          1                           1   \n",
       "4                          1                           1   \n",
       "\n",
       "   Tatsache_total_median  bereichernd_mixed_median  \n",
       "0                      0                         1  \n",
       "1                      0                         1  \n",
       "2                      0                         1  \n",
       "3                      0                         1  \n",
       "4                      1                         1  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvAsWbCPzHlN"
   },
   "source": [
    "## 2. Transform text for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1729086069282,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "YWdeQ69-zHOC"
   },
   "outputs": [],
   "source": [
    "sentences = df.c_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "311e839405b14da0a5e1207da92400f9",
      "6ad1774bccad4a8ea57bb78686b40957",
      "bd215e0ca74847118ba8a7c00429cac2",
      "066e549739d341818d9ccc76a264ae30",
      "86a8a6037dc744e2adb3d2e2deb5946b",
      "69d1b191bdbe47adbe37a0f3e7c68dc4",
      "25605175e36945a491de2aecdd653c46",
      "0196862b0e8d4d04b6bc8077247c98c6",
      "04f95987f8d84afbb0e344a6870cac7b",
      "bda31ca95fa14876b981bc3cc2874cc2",
      "dee3d7926b9e4c71bce69d233f4f2f8e",
      "81be217159c94fa4ad80131da2cbf843",
      "d896ea7dcfaa4c9494230c6646268aed",
      "1cf017a6706440d79ba58c3fa5f26e38",
      "7bfe52c53bf8458fa95d96632b6da289",
      "002be2421cee49b9bc5d4fb12e4a42e0",
      "72eaab231ff94c25b5568ca8640ca0d0",
      "5ad25b59e1e747f2a155cd1585888fe1",
      "2196ee353dd84ffc818d1c8c197e6058",
      "4f1e3641613449a3b2b0418038326bfd",
      "b6541e0304e24b34bdce0a4d6f2b8b38",
      "046f6e0480ac4e46b551021ee5b904e3",
      "4796ddabaefc44f281846d34f0a22f03",
      "c4a6ceb3c4234b01b04b1d32fb57afcd",
      "d1977360515f447ab2ba2fa6dcff4da6",
      "7e8e9ff2ce9b441eba07e0c5d5612660",
      "b897a71e5e264c8d9036d4d5361ae132",
      "4d9522d74317477dae9dba9675b4eab3",
      "c1c9fd4c308c475195449c41201fb2d8",
      "574f7feb86d5464c98777878924aec07",
      "72e9a1b0af3f4414981f9606c26ba7ce",
      "9c9455b1c891439b9666419c7b7e3e1b",
      "eabcf87c37f0422a865b7f92ea00a69f"
     ]
    },
    "executionInfo": {
     "elapsed": 2946,
     "status": "ok",
     "timestamp": 1729086077043,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "t8Wl9natyz5V",
    "outputId": "ef915e77-0018-4987-f153-3af6f0160c33"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-uncased\", use_fast = False, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31476,
     "status": "ok",
     "timestamp": 1729086117654,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "S4RYQplxysFm",
    "outputId": "698f689a-586a-47b8-dba2-879b3e8f3117"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Tolle Idee. Ich denke, dass dieses Projekt Teil des Stadtforums werden sollte, damit wir darüber weiter nachdenken können.\n",
      "Token IDs: [102, 11524, 4407, 552, 260, 5327, 806, 347, 971, 2354, 582, 210, 649, 30515, 318, 1370, 806, 865, 228, 449, 10360, 30940, 490, 18226, 367, 316, 552, 103]\n",
      "Legth: 28\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "\n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        #max_length = 128,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print(\"Legth:\", len(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729086117654,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "NoCnQe8tyBbX"
   },
   "outputs": [],
   "source": [
    "df[\"sequence_legth\"] = [len(sen) for sen in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 19887,
     "status": "ok",
     "timestamp": 1729086137539,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "pIJpMaBRx1uJ",
    "outputId": "8685c151-9aa3-4f1a-ebd7-b82ead8a3311"
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.bar(df.index, df[\"sequence_legth\"], width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729086137539,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "wxn2EK0tzqB7",
    "outputId": "59081e00-4a14-4021-dac6-099646f01af9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  3546\n",
      "Min sentence length:  3\n",
      "Mean sentence length:  77.44771098434987\n",
      "Median sentence length:  44.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n",
    "print('Min sentence length: ', min([len(sen) for sen in input_ids]))\n",
    "print('Mean sentence length: ', statistics.mean([len(sen) for sen in input_ids]))\n",
    "print('Median sentence length: ', statistics.median([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBdopa4VkvEo"
   },
   "source": [
    "## 3. Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Initialize BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 7926,
     "status": "ok",
     "timestamp": 1729086307473,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "9_z2rkWZkwv8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 664,
     "status": "ok",
     "timestamp": 1729087516341,
     "user": {
      "displayName": "Anke S.",
      "userId": "12382145308137163489"
     },
     "user_tz": -120
    },
    "id": "kc8PPYECgQ2-",
    "outputId": "995cd157-9016-479f-a7dc-37206065ff3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-uncased\", use_fast = False, do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"dbmdz/bert-base-german-uncased\", # deepset ai\n",
    "    num_labels = 2, # The number of output labels, which is 2 for binary classification.\n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "# Define a custom PyTorch dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask = encoding['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(label)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E04G7ahJiLlE"
   },
   "source": [
    "### 3.1 Low Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJytnosZkYc_"
   },
   "source": [
    "#### 3.1.1 Low on low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "0xiCsyQPkbXt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     36\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 37\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     38\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     39\u001b[0m     labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edulow_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IW6zTOlSkgzV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.740516</td>\n",
       "      <td>0.777070</td>\n",
       "      <td>0.707246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.878655</td>\n",
       "      <td>0.873282</td>\n",
       "      <td>0.910828</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.942771</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.894286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.981132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.985380</td>\n",
       "      <td>0.984227</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>0.996795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>0.996795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.996805</td>\n",
       "      <td>0.993631</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.995246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993651</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.990506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.996815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.995231</td>\n",
       "      <td>0.996815</td>\n",
       "      <td>0.993651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.990446</td>\n",
       "      <td>0.996795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.995608</td>\n",
       "      <td>0.995200</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.996795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.996795</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.973537</td>\n",
       "      <td>0.980411</td>\n",
       "      <td>0.967278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.750000  0.740516  0.777070   0.707246\n",
       "1     0.878655  0.873282  0.910828   0.838710\n",
       "2     0.944444  0.942771  0.996815   0.894286\n",
       "3     0.988304  0.987342  0.993631   0.981132\n",
       "4     0.997076  0.996825  1.000000   0.993671\n",
       "5     0.985380  0.984227  0.993631   0.975000\n",
       "6     0.994152  0.993610  0.990446   0.996795\n",
       "7     0.994152  0.993610  0.990446   0.996795\n",
       "8     0.997076  0.996805  0.993631   1.000000\n",
       "9     0.995614  0.995246  1.000000   0.990536\n",
       "10    0.998538  0.998410  1.000000   0.996825\n",
       "11    0.994152  0.993651  0.996815   0.990506\n",
       "12    0.997076  0.996815  0.996815   0.996815\n",
       "13    0.995614  0.995231  0.996815   0.993651\n",
       "14    0.994143  0.993610  0.990446   0.996795\n",
       "15    0.997072  0.996795  0.993610   1.000000\n",
       "16    0.995608  0.995200  0.993610   0.996795\n",
       "17    1.000000  1.000000  1.000000   1.000000\n",
       "18    1.000000  1.000000  1.000000   1.000000\n",
       "19    0.997072  0.996795  0.993610   1.000000\n",
       "mean  0.974706  0.973537  0.980411   0.967278"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new df\n",
    "df_low_low = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_low_low.loc['mean'] = df_low_low.mean()\n",
    "df_low_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "L4gxsllUkg2u"
   },
   "outputs": [],
   "source": [
    "df_low_low.to_excel('df_low_low.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VYAsbkBkQ42"
   },
   "source": [
    "#### 3.1.2 Low on Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOjAzMeRo8R0",
    "outputId": "38e63e2c-dd70-48e8-a1fd-a93f41a038b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7426900584795322\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7397660818713451\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7368421052631579\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.7587719298245614\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.7543859649122807\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7631578947368421\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.7631578947368421\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7353801169590644\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7426900584795322\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.75\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7134502923976608\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7353801169590644\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7529239766081871\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7616959064327485\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7642752562225475\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7628111273792094\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7540263543191801\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.767203513909224\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7496339677891655\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7481698389458272\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edulow_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oFMzYELNrWsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7426900584795322,\n",
       " 0.7397660818713451,\n",
       " 0.7368421052631579,\n",
       " 0.7587719298245614,\n",
       " 0.7543859649122807,\n",
       " 0.7631578947368421,\n",
       " 0.7631578947368421,\n",
       " 0.7353801169590644,\n",
       " 0.7426900584795322,\n",
       " 0.75,\n",
       " 0.7134502923976608,\n",
       " 0.7353801169590644,\n",
       " 0.7529239766081871,\n",
       " 0.7616959064327485,\n",
       " 0.7642752562225475,\n",
       " 0.7628111273792094,\n",
       " 0.7540263543191801,\n",
       " 0.767203513909224,\n",
       " 0.7496339677891655,\n",
       " 0.7481698389458272]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RUSzQbLNrfjh"
   },
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_low_med = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "_2usZcUswLY5"
   },
   "outputs": [],
   "source": [
    "#Add row with mean\n",
    "df_low_med.loc['mean'] = df_low_med.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "H1RCi51P0etr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>0.705015</td>\n",
       "      <td>0.758730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739766</td>\n",
       "      <td>0.731118</td>\n",
       "      <td>0.705539</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.688202</td>\n",
       "      <td>0.780255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.754098</td>\n",
       "      <td>0.706704</td>\n",
       "      <td>0.808307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.749254</td>\n",
       "      <td>0.709040</td>\n",
       "      <td>0.794304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.752294</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.763975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.756024</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.799363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.735380</td>\n",
       "      <td>0.721966</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.743671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.707736</td>\n",
       "      <td>0.781646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.710914</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.762658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.735380</td>\n",
       "      <td>0.726172</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.752924</td>\n",
       "      <td>0.739599</td>\n",
       "      <td>0.712166</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.754887</td>\n",
       "      <td>0.713068</td>\n",
       "      <td>0.801917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.730539</td>\n",
       "      <td>0.774603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.762811</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.725373</td>\n",
       "      <td>0.776358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.754026</td>\n",
       "      <td>0.739938</td>\n",
       "      <td>0.711310</td>\n",
       "      <td>0.770968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.767204</td>\n",
       "      <td>0.760902</td>\n",
       "      <td>0.714689</td>\n",
       "      <td>0.813505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.749634</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.716012</td>\n",
       "      <td>0.754777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.748170</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.708709</td>\n",
       "      <td>0.758842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.749821</td>\n",
       "      <td>0.740266</td>\n",
       "      <td>0.708526</td>\n",
       "      <td>0.775338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.742690  0.730887  0.705015   0.758730\n",
       "1     0.739766  0.731118  0.705539   0.758621\n",
       "2     0.736842  0.731343  0.688202   0.780255\n",
       "3     0.758772  0.754098  0.706704   0.808307\n",
       "4     0.754386  0.749254  0.709040   0.794304\n",
       "5     0.763158  0.752294  0.740964   0.763975\n",
       "6     0.763158  0.756024  0.717143   0.799363\n",
       "7     0.735380  0.721966  0.701493   0.743671\n",
       "8     0.742690  0.733333  0.699422   0.770701\n",
       "9     0.750000  0.742857  0.707736   0.781646\n",
       "10    0.713450  0.710914  0.665746   0.762658\n",
       "11    0.735380  0.726172  0.691643   0.764331\n",
       "12    0.752924  0.739599  0.712166   0.769231\n",
       "13    0.761696  0.754887  0.713068   0.801917\n",
       "14    0.764275  0.751926  0.730539   0.774603\n",
       "15    0.762811  0.750000  0.725373   0.776358\n",
       "16    0.754026  0.739938  0.711310   0.770968\n",
       "17    0.767204  0.760902  0.714689   0.813505\n",
       "18    0.749634  0.734884  0.716012   0.754777\n",
       "19    0.748170  0.732919  0.708709   0.758842\n",
       "mean  0.749821  0.740266  0.708526   0.775338"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_low_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "M9-5UkQA6OwX"
   },
   "outputs": [],
   "source": [
    "df_low_med.to_excel('df_low_med.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TF290ROtWLH"
   },
   "source": [
    "#### 3.1.3 Low on high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOjAzMeRo8R0",
    "outputId": "38e63e2c-dd70-48e8-a1fd-a93f41a038b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7280701754385965\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7178362573099415\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7602339181286549\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.7821637426900585\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.7514619883040936\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7412280701754386\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.7456140350877193\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7441520467836257\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.72953216374269\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.7456140350877193\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7573099415204678\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7397660818713451\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7558479532163743\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7675438596491229\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7247437774524158\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7437774524158126\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7642752562225475\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.7452415812591509\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7569546120058566\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7232796486090776\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edulow_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RUSzQbLNrfjh"
   },
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_low_high = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_low_high.loc['mean'] = df_low_high.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "H1RCi51P0etr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728070</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.717836</td>\n",
       "      <td>0.696063</td>\n",
       "      <td>0.686335</td>\n",
       "      <td>0.706070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.746130</td>\n",
       "      <td>0.728097</td>\n",
       "      <td>0.765079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.782164</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.751534</td>\n",
       "      <td>0.782748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.719033</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.724728</td>\n",
       "      <td>0.703927</td>\n",
       "      <td>0.746795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.732308</td>\n",
       "      <td>0.710448</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.744152</td>\n",
       "      <td>0.726989</td>\n",
       "      <td>0.710366</td>\n",
       "      <td>0.744409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.729532</td>\n",
       "      <td>0.714946</td>\n",
       "      <td>0.692537</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.713855</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.757310</td>\n",
       "      <td>0.746177</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.739766</td>\n",
       "      <td>0.721875</td>\n",
       "      <td>0.706422</td>\n",
       "      <td>0.738019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.755848</td>\n",
       "      <td>0.732800</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.724684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.751174</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.724744</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.708197</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.743777</td>\n",
       "      <td>0.722662</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.728435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.743222</td>\n",
       "      <td>0.735016</td>\n",
       "      <td>0.751613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.745242</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.711246</td>\n",
       "      <td>0.747604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.756955</td>\n",
       "      <td>0.742236</td>\n",
       "      <td>0.719880</td>\n",
       "      <td>0.766026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.723280</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.702265</td>\n",
       "      <td>0.691083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.746232</td>\n",
       "      <td>0.728180</td>\n",
       "      <td>0.715794</td>\n",
       "      <td>0.741333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.728070  0.704762  0.702532   0.707006\n",
       "1     0.717836  0.696063  0.686335   0.706070\n",
       "2     0.760234  0.746130  0.728097   0.765079\n",
       "3     0.782164  0.766823  0.751534   0.782748\n",
       "4     0.751462  0.736842  0.719033   0.755556\n",
       "5     0.741228  0.724728  0.703927   0.746795\n",
       "6     0.745614  0.732308  0.710448   0.755556\n",
       "7     0.744152  0.726989  0.710366   0.744409\n",
       "8     0.729532  0.714946  0.692537   0.738854\n",
       "9     0.745614  0.731481  0.713855   0.750000\n",
       "10    0.757310  0.746177  0.717647   0.777070\n",
       "11    0.739766  0.721875  0.706422   0.738019\n",
       "12    0.755848  0.732800  0.741100   0.724684\n",
       "13    0.767544  0.751174  0.738462   0.764331\n",
       "14    0.724744  0.696774  0.708197   0.685714\n",
       "15    0.743777  0.722662  0.716981   0.728435\n",
       "16    0.764275  0.743222  0.735016   0.751613\n",
       "17    0.745242  0.728972  0.711246   0.747604\n",
       "18    0.756955  0.742236  0.719880   0.766026\n",
       "19    0.723280  0.696629  0.702265   0.691083\n",
       "mean  0.746232  0.728180  0.715794   0.741333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_low_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "M9-5UkQA6OwX"
   },
   "outputs": [],
   "source": [
    "df_low_high.to_excel('df_low_high.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uawj-7AwtY4T"
   },
   "source": [
    "#### 3.1.4 Low on mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sOjAzMeRo8R0",
    "outputId": "38e63e2c-dd70-48e8-a1fd-a93f41a038b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.77046783625731\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7850877192982456\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7748538011695907\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8216374269005848\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.7880116959064327\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7953216374269005\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8084795321637427\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7967836257309941\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7909356725146199\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.7894736842105263\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.8230994152046783\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7923976608187134\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.8216374269005848\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.8201754385964912\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7642752562225475\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7906295754026355\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7920937042459737\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8023426061493412\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.821376281112738\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.787701317715959\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edulow_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "RUSzQbLNrfjh"
   },
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_low_mix = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_low_mix.loc['mean'] = df_low_mix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "H1RCi51P0etr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.755832</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.776358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.772798</td>\n",
       "      <td>0.750751</td>\n",
       "      <td>0.796178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.761610</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.785942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.809969</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.828025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.788012</td>\n",
       "      <td>0.777948</td>\n",
       "      <td>0.749263</td>\n",
       "      <td>0.808917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.781931</td>\n",
       "      <td>0.765244</td>\n",
       "      <td>0.799363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.797527</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.824281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.796784</td>\n",
       "      <td>0.779014</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.780255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.755224</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.815287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.823099</td>\n",
       "      <td>0.811232</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.822785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.792398</td>\n",
       "      <td>0.780186</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.805112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.809375</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.832797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.837580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.748830</td>\n",
       "      <td>0.736196</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.790630</td>\n",
       "      <td>0.768233</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.769481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.792094</td>\n",
       "      <td>0.775316</td>\n",
       "      <td>0.763240</td>\n",
       "      <td>0.787781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.802343</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.768072</td>\n",
       "      <td>0.814696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.821376</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>0.805732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.787701</td>\n",
       "      <td>0.768740</td>\n",
       "      <td>0.757862</td>\n",
       "      <td>0.779935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.796839</td>\n",
       "      <td>0.783280</td>\n",
       "      <td>0.765710</td>\n",
       "      <td>0.801907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.770468  0.755832  0.736364   0.776358\n",
       "1     0.785088  0.772798  0.750751   0.796178\n",
       "2     0.774854  0.761610  0.738739   0.785942\n",
       "3     0.821637  0.809969  0.792683   0.828025\n",
       "4     0.788012  0.777948  0.749263   0.808917\n",
       "5     0.795322  0.781931  0.765244   0.799363\n",
       "6     0.808480  0.797527  0.772455   0.824281\n",
       "7     0.796784  0.779014  0.777778   0.780255\n",
       "8     0.790936  0.779661  0.755224   0.805732\n",
       "9     0.789474  0.780488  0.748538   0.815287\n",
       "10    0.823099  0.811232  0.800000   0.822785\n",
       "11    0.792398  0.780186  0.756757   0.805112\n",
       "12    0.821637  0.809375  0.787234   0.832797\n",
       "13    0.820175  0.810478  0.785075   0.837580\n",
       "14    0.764275  0.748830  0.736196   0.761905\n",
       "15    0.790630  0.768233  0.766990   0.769481\n",
       "16    0.792094  0.775316  0.763240   0.787781\n",
       "17    0.802343  0.790698  0.768072   0.814696\n",
       "18    0.821376  0.805732  0.805732   0.805732\n",
       "19    0.787701  0.768740  0.757862   0.779935\n",
       "mean  0.796839  0.783280  0.765710   0.801907"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_low_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "M9-5UkQA6OwX"
   },
   "outputs": [],
   "source": [
    "df_low_mix.to_excel('df_low_mix.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjOdvxuI1iZD"
   },
   "source": [
    "## 3.2 Education Medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1  Medium on low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "cyUa0NIE1zDH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.868421052631579\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7850877192982456\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7324561403508771\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.75\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.7953216374269005\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7353801169590644\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.7763157894736842\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7909356725146199\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7339181286549707\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.75\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7192982456140351\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7675438596491229\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7573099415204678\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7514619883040936\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7306002928257687\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7335285505124451\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7291361639824304\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.7496339677891655\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7174231332357247\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7657393850658858\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edumed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "s1Hhc9fn2KQW"
   },
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_med_low = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_med_low.loc['mean'] = df_med_low.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xQ9LclT_3XIa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.917722</td>\n",
       "      <td>0.819209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.726761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.732456</td>\n",
       "      <td>0.731278</td>\n",
       "      <td>0.787975</td>\n",
       "      <td>0.682192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.758133</td>\n",
       "      <td>0.795252</td>\n",
       "      <td>0.724324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.845161</td>\n",
       "      <td>0.740113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.735380</td>\n",
       "      <td>0.720247</td>\n",
       "      <td>0.774086</td>\n",
       "      <td>0.673410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.775330</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.783661</td>\n",
       "      <td>0.817035</td>\n",
       "      <td>0.752907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.733918</td>\n",
       "      <td>0.727545</td>\n",
       "      <td>0.747692</td>\n",
       "      <td>0.708455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>0.778135</td>\n",
       "      <td>0.703488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.700935</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.646552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.763744</td>\n",
       "      <td>0.793210</td>\n",
       "      <td>0.736390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.757310</td>\n",
       "      <td>0.739812</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.688047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.743976</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.728614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.730600</td>\n",
       "      <td>0.711599</td>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.657971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.733529</td>\n",
       "      <td>0.720859</td>\n",
       "      <td>0.767974</td>\n",
       "      <td>0.679191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.729136</td>\n",
       "      <td>0.726736</td>\n",
       "      <td>0.736527</td>\n",
       "      <td>0.717201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.749634</td>\n",
       "      <td>0.731554</td>\n",
       "      <td>0.787162</td>\n",
       "      <td>0.683284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.717423</td>\n",
       "      <td>0.708899</td>\n",
       "      <td>0.741325</td>\n",
       "      <td>0.679191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.720461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.748696</td>\n",
       "      <td>0.790454</td>\n",
       "      <td>0.711760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.868421  0.865672  0.917722   0.819209\n",
       "1     0.785088  0.778281  0.837662   0.726761\n",
       "2     0.732456  0.731278  0.787975   0.682192\n",
       "3     0.750000  0.758133  0.795252   0.724324\n",
       "4     0.795322  0.789157  0.845161   0.740113\n",
       "5     0.735380  0.720247  0.774086   0.673410\n",
       "6     0.776316  0.775330  0.783383   0.767442\n",
       "7     0.790936  0.783661  0.817035   0.752907\n",
       "8     0.733918  0.727545  0.747692   0.708455\n",
       "9     0.750000  0.738931  0.778135   0.703488\n",
       "10    0.719298  0.700935  0.765306   0.646552\n",
       "11    0.767544  0.763744  0.793210   0.736390\n",
       "12    0.757310  0.739812  0.800000   0.688047\n",
       "13    0.751462  0.743976  0.760000   0.728614\n",
       "14    0.730600  0.711599  0.774744   0.657971\n",
       "15    0.733529  0.720859  0.767974   0.679191\n",
       "16    0.729136  0.726736  0.736527   0.717201\n",
       "17    0.749634  0.731554  0.787162   0.683284\n",
       "18    0.717423  0.708899  0.741325   0.679191\n",
       "19    0.765739  0.757576  0.798722   0.720461\n",
       "mean  0.756976  0.748696  0.790454   0.711760"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "wEu6TKVl6HhW"
   },
   "outputs": [],
   "source": [
    "df_med_low.to_excel('df_med_low.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2  Medium on medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.9897660818713451\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.9970760233918129\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.922514619883041\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8640350877192983\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.9897660818713451\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.9649122807017544\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.9809941520467836\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.9985380116959064\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.9941520467836257\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.6871345029239766\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.9283625730994152\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.9722222222222222\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.9678362573099415\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.9853801169590644\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.972181551976574\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.9809663250366032\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.9912152269399708\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.9824304538799414\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.9663250366032211\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.9838945827232797\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edumed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_med_med = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_med_med.loc['mean'] = df_med_med.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989766</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.994203</td>\n",
       "      <td>0.985632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.997101</td>\n",
       "      <td>0.997101</td>\n",
       "      <td>0.997101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.922515</td>\n",
       "      <td>0.928475</td>\n",
       "      <td>0.997101</td>\n",
       "      <td>0.868687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.864035</td>\n",
       "      <td>0.880616</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.788506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989766</td>\n",
       "      <td>0.989811</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.991254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.933140</td>\n",
       "      <td>0.996894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.980994</td>\n",
       "      <td>0.981077</td>\n",
       "      <td>0.979651</td>\n",
       "      <td>0.982507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.994220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.687135</td>\n",
       "      <td>0.762222</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.616906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.928363</td>\n",
       "      <td>0.932969</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>0.881137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.972896</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>0.955182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.967836</td>\n",
       "      <td>0.967164</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.993865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.985380</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.988304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.972182</td>\n",
       "      <td>0.972018</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>0.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.980966</td>\n",
       "      <td>0.981349</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>0.968839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.991215</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>0.988439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.982430</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>0.985465</td>\n",
       "      <td>0.979769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.966325</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>0.973451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.983895</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.991279</td>\n",
       "      <td>0.977077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.955985</td>\n",
       "      <td>0.961106</td>\n",
       "      <td>0.983723</td>\n",
       "      <td>0.945212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.989766  0.989899  0.994203   0.985632\n",
       "1     0.997076  0.997101  0.997101   0.997101\n",
       "2     0.922515  0.928475  0.997101   0.868687\n",
       "3     0.864035  0.880616  0.997093   0.788506\n",
       "4     0.989766  0.989811  0.988372   0.991254\n",
       "5     0.964912  0.963964  0.933140   0.996894\n",
       "6     0.980994  0.981077  0.979651   0.982507\n",
       "7     0.998538  0.998549  1.000000   0.997101\n",
       "8     0.994152  0.994220  1.000000   0.988506\n",
       "9     0.687135  0.762222  0.997093   0.616906\n",
       "10    0.928363  0.932969  0.991279   0.881137\n",
       "11    0.972222  0.972896  0.991279   0.955182\n",
       "12    0.967836  0.967164  0.941860   0.993865\n",
       "13    0.985380  0.985423  0.982558   0.988304\n",
       "14    0.972182  0.972018  0.959302   0.985075\n",
       "15    0.980966  0.981349  0.994186   0.968839\n",
       "16    0.991215  0.991304  0.994186   0.988439\n",
       "17    0.982430  0.982609  0.985465   0.979769\n",
       "18    0.966325  0.966325  0.959302   0.973451\n",
       "19    0.983895  0.984127  0.991279   0.977077\n",
       "mean  0.955985  0.961106  0.983723   0.945212"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_med.to_excel('df_med_med.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3  Medium on high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7909356725146199\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7763157894736842\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7485380116959064\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.7690058479532164\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.7777777777777778\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.814327485380117\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.7733918128654971\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.8026315789473685\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7894736842105263\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.7777777777777778\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7777777777777778\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7529239766081871\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7660818713450293\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.804093567251462\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7759882869692533\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7657393850658858\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7935578330893118\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.7774524158125915\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7715959004392386\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7920937042459737\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edumed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_med_high = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_med_high.loc['mean'] = df_med_high.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.787519</td>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.735211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.737003</td>\n",
       "      <td>0.779935</td>\n",
       "      <td>0.698551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.763473</td>\n",
       "      <td>0.806962</td>\n",
       "      <td>0.724432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.772455</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.745665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.809023</td>\n",
       "      <td>0.851266</td>\n",
       "      <td>0.770774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.773392</td>\n",
       "      <td>0.769001</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.743516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.791988</td>\n",
       "      <td>0.769461</td>\n",
       "      <td>0.815873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.773913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.754821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.770393</td>\n",
       "      <td>0.812102</td>\n",
       "      <td>0.732759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.752924</td>\n",
       "      <td>0.756133</td>\n",
       "      <td>0.850649</td>\n",
       "      <td>0.680519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.766467</td>\n",
       "      <td>0.757396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.804094</td>\n",
       "      <td>0.800595</td>\n",
       "      <td>0.820122</td>\n",
       "      <td>0.781977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.775988</td>\n",
       "      <td>0.775330</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.751553</td>\n",
       "      <td>0.798680</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.777452</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.795107</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.771596</td>\n",
       "      <td>0.770588</td>\n",
       "      <td>0.777448</td>\n",
       "      <td>0.763848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.792094</td>\n",
       "      <td>0.793003</td>\n",
       "      <td>0.804734</td>\n",
       "      <td>0.781609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.776205</td>\n",
       "      <td>0.804092</td>\n",
       "      <td>0.751354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.790936  0.787519  0.820433   0.757143\n",
       "1     0.776316  0.773333  0.815625   0.735211\n",
       "2     0.748538  0.737003  0.779935   0.698551\n",
       "3     0.769006  0.763473  0.806962   0.724432\n",
       "4     0.777778  0.772455  0.801242   0.745665\n",
       "5     0.814327  0.809023  0.851266   0.770774\n",
       "6     0.773392  0.769001  0.796296   0.743516\n",
       "7     0.802632  0.791988  0.769461   0.815873\n",
       "8     0.789474  0.787611  0.801802   0.773913\n",
       "9     0.777778  0.782857  0.813056   0.754821\n",
       "10    0.777778  0.770393  0.812102   0.732759\n",
       "11    0.752924  0.756133  0.850649   0.680519\n",
       "12    0.766082  0.761905  0.766467   0.757396\n",
       "13    0.804094  0.800595  0.820122   0.781977\n",
       "14    0.775988  0.775330  0.807339   0.745763\n",
       "15    0.765739  0.751553  0.798680   0.709677\n",
       "16    0.793558  0.796537  0.793103   0.800000\n",
       "17    0.777452  0.773810  0.795107   0.753623\n",
       "18    0.771596  0.770588  0.777448   0.763848\n",
       "19    0.792094  0.793003  0.804734   0.781609\n",
       "mean  0.779874  0.776205  0.804092   0.751354"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_high.to_excel('df_med_high.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Medium on mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.8289473684210527\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.8304093567251462\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.8026315789473685\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.7997076023391813\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.4853801169590643\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.8260233918128655\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8099415204678363\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.8464912280701754\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.804093567251462\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.8070175438596491\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.8070175438596491\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.8230994152046783\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.8230994152046783\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.814327485380117\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7964860907759883\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7964860907759883\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.8257686676427526\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8316251830161054\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.8125915080527086\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.83601756954612\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_edumed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_med_mix = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_med_mix.loc['mean'] = df_med_mix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.824060</td>\n",
       "      <td>0.858934</td>\n",
       "      <td>0.791908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.827893</td>\n",
       "      <td>0.850610</td>\n",
       "      <td>0.806358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.798808</td>\n",
       "      <td>0.819572</td>\n",
       "      <td>0.779070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.805389</td>\n",
       "      <td>0.788856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.652860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.826023</td>\n",
       "      <td>0.821589</td>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.782857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.809942</td>\n",
       "      <td>0.811047</td>\n",
       "      <td>0.835329</td>\n",
       "      <td>0.788136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.846491</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.850440</td>\n",
       "      <td>0.843023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.804094</td>\n",
       "      <td>0.798193</td>\n",
       "      <td>0.812883</td>\n",
       "      <td>0.784024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.810888</td>\n",
       "      <td>0.815562</td>\n",
       "      <td>0.806268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.747826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.823099</td>\n",
       "      <td>0.821797</td>\n",
       "      <td>0.850610</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.823099</td>\n",
       "      <td>0.818045</td>\n",
       "      <td>0.852665</td>\n",
       "      <td>0.786127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.813510</td>\n",
       "      <td>0.824405</td>\n",
       "      <td>0.802899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.796486</td>\n",
       "      <td>0.788432</td>\n",
       "      <td>0.824841</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.796486</td>\n",
       "      <td>0.787786</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.825769</td>\n",
       "      <td>0.830243</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.831429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.831625</td>\n",
       "      <td>0.828614</td>\n",
       "      <td>0.847561</td>\n",
       "      <td>0.810496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.812592</td>\n",
       "      <td>0.810089</td>\n",
       "      <td>0.822289</td>\n",
       "      <td>0.798246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.836018</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.822157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.800358</td>\n",
       "      <td>0.805911</td>\n",
       "      <td>0.844621</td>\n",
       "      <td>0.777714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.828947  0.824060  0.858934   0.791908\n",
       "1     0.830409  0.827893  0.850610   0.806358\n",
       "2     0.802632  0.798808  0.819572   0.779070\n",
       "3     0.799708  0.797037  0.805389   0.788856\n",
       "4     0.485380  0.652860  1.000000   0.484627\n",
       "5     0.826023  0.821589  0.864353   0.782857\n",
       "6     0.809942  0.811047  0.835329   0.788136\n",
       "7     0.846491  0.846715  0.850440   0.843023\n",
       "8     0.804094  0.798193  0.812883   0.784024\n",
       "9     0.807018  0.810888  0.815562   0.806268\n",
       "10    0.807018  0.796296  0.851485   0.747826\n",
       "11    0.823099  0.821797  0.850610   0.794872\n",
       "12    0.823099  0.818045  0.852665   0.786127\n",
       "13    0.814327  0.813510  0.824405   0.802899\n",
       "14    0.796486  0.788432  0.824841   0.755102\n",
       "15    0.796486  0.787786  0.829582   0.750000\n",
       "16    0.825769  0.830243  0.829060   0.831429\n",
       "17    0.831625  0.828614  0.847561   0.810496\n",
       "18    0.812592  0.810089  0.822289   0.798246\n",
       "19    0.836018  0.834320  0.846847   0.822157\n",
       "mean  0.800358  0.805911  0.844621   0.777714"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_mix.to_excel('df_med_mix.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-FyiHVQ4wiL"
   },
   "source": [
    "### 3.3 Education High"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 High on low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "k0C05pcI43LX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7748538011695907\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.8523391812865497\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.6564327485380117\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8187134502923976\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8011695906432749\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.8201754385964912\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8157894736842105\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7880116959064327\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7909356725146199\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.77046783625731\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7558479532163743\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.5248538011695907\n",
      "Training Fold 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Fold 13: 0.7733918128654971\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7807017543859649\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.746705710102489\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.780380673499268\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7642752562225475\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.7657393850658858\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7598828696925329\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7569546120058566\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Low in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_eduhigh_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_high_low = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_high_low.loc['mean'] = df_high_low.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.754777</td>\n",
       "      <td>0.779605</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.852339</td>\n",
       "      <td>0.818018</td>\n",
       "      <td>0.782759</td>\n",
       "      <td>0.856604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.656433</td>\n",
       "      <td>0.430993</td>\n",
       "      <td>0.281646</td>\n",
       "      <td>0.917526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.834951</td>\n",
       "      <td>0.779456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.793313</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.788520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.864353</td>\n",
       "      <td>0.774011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.813056</td>\n",
       "      <td>0.840491</td>\n",
       "      <td>0.787356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.788012</td>\n",
       "      <td>0.776579</td>\n",
       "      <td>0.812903</td>\n",
       "      <td>0.743363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.777605</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.739645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.766716</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.714681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.755848</td>\n",
       "      <td>0.763121</td>\n",
       "      <td>0.830247</td>\n",
       "      <td>0.706037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.524854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.773392</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.780781</td>\n",
       "      <td>0.760234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.804954</td>\n",
       "      <td>0.749280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.746706</td>\n",
       "      <td>0.730949</td>\n",
       "      <td>0.785953</td>\n",
       "      <td>0.683140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.780381</td>\n",
       "      <td>0.775449</td>\n",
       "      <td>0.811912</td>\n",
       "      <td>0.742120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.764275</td>\n",
       "      <td>0.745656</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.692082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.748428</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.734568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.759883</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.719033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.756955</td>\n",
       "      <td>0.746177</td>\n",
       "      <td>0.755418</td>\n",
       "      <td>0.737160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764881</td>\n",
       "      <td>0.717701</td>\n",
       "      <td>0.737600</td>\n",
       "      <td>0.717815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.774854  0.754777  0.779605   0.731481\n",
       "1     0.852339  0.818018  0.782759   0.856604\n",
       "2     0.656433  0.430993  0.281646   0.917526\n",
       "3     0.818713  0.806250  0.834951   0.779456\n",
       "4     0.801170  0.793313  0.798165   0.788520\n",
       "5     0.820175  0.816692  0.864353   0.774011\n",
       "6     0.815789  0.813056  0.840491   0.787356\n",
       "7     0.788012  0.776579  0.812903   0.743363\n",
       "8     0.790936  0.777605  0.819672   0.739645\n",
       "9     0.770468  0.766716  0.826923   0.714681\n",
       "10    0.755848  0.763121  0.830247   0.706037\n",
       "11    0.524854  0.000000  0.000000   0.000000\n",
       "12    0.773392  0.770370  0.780781   0.760234\n",
       "13    0.780702  0.776119  0.804954   0.749280\n",
       "14    0.746706  0.730949  0.785953   0.683140\n",
       "15    0.780381  0.775449  0.811912   0.742120\n",
       "16    0.764275  0.745656  0.808219   0.692082\n",
       "17    0.765739  0.748428  0.762821   0.734568\n",
       "18    0.759883  0.743750  0.770227   0.719033\n",
       "19    0.756955  0.746177  0.755418   0.737160\n",
       "mean  0.764881  0.717701  0.737600   0.717815"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_low.to_excel('df_high_low.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 High on medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7997076023391813\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.814327485380117\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.7982456140350878\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.7850877192982456\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8172514619883041\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7997076023391813\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8099415204678363\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7456140350877193\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7880116959064327\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.7821637426900585\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.7690058479532164\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.7909356725146199\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7821637426900585\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7880116959064327\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7525622254758418\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7730600292825769\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.7540263543191801\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8023426061493412\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.83601756954612\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.8008784773060029\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Medium in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_eduhigh_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_high_med = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_high_med.loc['mean'] = df_high_med.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.801161</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.809384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.814056</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.834835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.751479</td>\n",
       "      <td>0.824675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.780269</td>\n",
       "      <td>0.711172</td>\n",
       "      <td>0.864238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.817251</td>\n",
       "      <td>0.813711</td>\n",
       "      <td>0.793605</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.787356</td>\n",
       "      <td>0.813056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.809942</td>\n",
       "      <td>0.808260</td>\n",
       "      <td>0.776204</td>\n",
       "      <td>0.843077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.670487</td>\n",
       "      <td>0.798635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.788012</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.803030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.782164</td>\n",
       "      <td>0.781845</td>\n",
       "      <td>0.758523</td>\n",
       "      <td>0.806647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.762763</td>\n",
       "      <td>0.736232</td>\n",
       "      <td>0.791277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.790936</td>\n",
       "      <td>0.777605</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.782164</td>\n",
       "      <td>0.783115</td>\n",
       "      <td>0.751397</td>\n",
       "      <td>0.817629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.788012</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.777439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.752562</td>\n",
       "      <td>0.741985</td>\n",
       "      <td>0.734139</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.773060</td>\n",
       "      <td>0.771723</td>\n",
       "      <td>0.738028</td>\n",
       "      <td>0.808642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.754026</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>0.722857</td>\n",
       "      <td>0.780864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.802343</td>\n",
       "      <td>0.793262</td>\n",
       "      <td>0.784848</td>\n",
       "      <td>0.801858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.836018</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.809249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.800878</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.789157</td>\n",
       "      <td>0.798780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.789453</td>\n",
       "      <td>0.784346</td>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.808993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.799708  0.801161  0.793103   0.809384\n",
       "1     0.814327  0.814056  0.794286   0.834835\n",
       "2     0.798246  0.786378  0.751479   0.824675\n",
       "3     0.785088  0.780269  0.711172   0.864238\n",
       "4     0.817251  0.813711  0.793605   0.834862\n",
       "5     0.799708  0.800000  0.787356   0.813056\n",
       "6     0.809942  0.808260  0.776204   0.843077\n",
       "7     0.745614  0.728972  0.670487   0.798635\n",
       "8     0.788012  0.785185  0.768116   0.803030\n",
       "9     0.782164  0.781845  0.758523   0.806647\n",
       "10    0.769006  0.762763  0.736232   0.791277\n",
       "11    0.790936  0.777605  0.746269   0.811688\n",
       "12    0.782164  0.783115  0.751397   0.817629\n",
       "13    0.788012  0.778626  0.779817   0.777439\n",
       "14    0.752562  0.741985  0.734139   0.750000\n",
       "15    0.773060  0.771723  0.738028   0.808642\n",
       "16    0.754026  0.750742  0.722857   0.780864\n",
       "17    0.802343  0.793262  0.784848   0.801858\n",
       "18    0.836018  0.833333  0.858896   0.809249\n",
       "19    0.800878  0.793939  0.789157   0.798780\n",
       "mean  0.789453  0.784346  0.762298   0.808993"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_med.to_excel('df_high_med.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 High on high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.9766081871345029\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.5350877192982456\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.9619883040935673\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.9926900584795322\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.9181286549707602\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.9824561403508771\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.9883040935672515\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.9941520467836257\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.9912280701754386\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.9897660818713451\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.9941520467836257\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.4766081871345029\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.9956140350877193\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.9985380116959064\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.9692532942898975\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.9736456808199122\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.9824304538799414\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.9853587115666179\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.9853587115666179\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.9809663250366032\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_eduhigh_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_high_high = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_high_high.loc['mean'] = df_high_high.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976608</td>\n",
       "      <td>0.975460</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.972477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535088</td>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.961988</td>\n",
       "      <td>0.960123</td>\n",
       "      <td>0.963077</td>\n",
       "      <td>0.957187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.992320</td>\n",
       "      <td>0.993846</td>\n",
       "      <td>0.990798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918129</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.836923</td>\n",
       "      <td>0.989091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.978462</td>\n",
       "      <td>0.984520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.988304</td>\n",
       "      <td>0.987616</td>\n",
       "      <td>0.981538</td>\n",
       "      <td>0.993769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.996904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.990769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.989766</td>\n",
       "      <td>0.989214</td>\n",
       "      <td>0.987692</td>\n",
       "      <td>0.990741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993827</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.996904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.476608</td>\n",
       "      <td>0.642715</td>\n",
       "      <td>0.990769</td>\n",
       "      <td>0.475628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.995392</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>0.993865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998459</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.969253</td>\n",
       "      <td>0.966614</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.984227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.982430</td>\n",
       "      <td>0.981366</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.985359</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>0.993730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.985359</td>\n",
       "      <td>0.984424</td>\n",
       "      <td>0.975309</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.980966</td>\n",
       "      <td>0.979782</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.987461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.933617</td>\n",
       "      <td>0.915933</td>\n",
       "      <td>0.924453</td>\n",
       "      <td>0.964119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.976608  0.975460  0.978462   0.972477\n",
       "1     0.535088  0.042169  0.021538   1.000000\n",
       "2     0.961988  0.960123  0.963077   0.957187\n",
       "3     0.992690  0.992320  0.993846   0.990798\n",
       "4     0.918129  0.906667  0.836923   0.989091\n",
       "5     0.982456  0.981481  0.978462   0.984520\n",
       "6     0.988304  0.987616  0.981538   0.993769\n",
       "7     0.994152  0.993827  0.990769   0.996904\n",
       "8     0.991228  0.990769  0.990769   0.990769\n",
       "9     0.989766  0.989214  0.987692   0.990741\n",
       "10    0.994152  0.993827  0.990769   0.996904\n",
       "11    0.476608  0.642715  0.990769   0.475628\n",
       "12    0.995614  0.995392  0.996923   0.993865\n",
       "13    0.998538  0.998459  0.996923   1.000000\n",
       "14    0.969253  0.966614  0.935385   1.000000\n",
       "15    0.973646  0.971963  0.960000   0.984227\n",
       "16    0.982430  0.981366  0.972308   0.990596\n",
       "17    0.985359  0.984472  0.975385   0.993730\n",
       "18    0.985359  0.984424  0.975309   0.993711\n",
       "19    0.980966  0.979782  0.972222   0.987461\n",
       "mean  0.933617  0.915933  0.924453   0.964119"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_high.to_excel('df_high_high.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.4 High on mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.8187134502923976\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.8201754385964912\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.8377192982456141\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8362573099415205\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8464912280701754\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.8391812865497076\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.814327485380117\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.7821637426900585\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7616959064327485\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.8084795321637427\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.5\n",
      "Training Fold 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Fold 12: 0.7997076023391813\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.8026315789473685\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.8362573099415205\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7862371888726208\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.5402635431918009\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.8330893118594437\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8316251830161054\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.8301610541727672\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.8125915080527086\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_eduhigh_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_high_mix = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_high_mix.loc['mean'] = df_high_mix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.817910</td>\n",
       "      <td>0.813056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.809302</td>\n",
       "      <td>0.825949</td>\n",
       "      <td>0.793313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.832073</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.843558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.802292</td>\n",
       "      <td>0.866873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.846491</td>\n",
       "      <td>0.836703</td>\n",
       "      <td>0.822630</td>\n",
       "      <td>0.851266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.839181</td>\n",
       "      <td>0.830247</td>\n",
       "      <td>0.832817</td>\n",
       "      <td>0.827692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.814327</td>\n",
       "      <td>0.812960</td>\n",
       "      <td>0.838906</td>\n",
       "      <td>0.788571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.782164</td>\n",
       "      <td>0.774584</td>\n",
       "      <td>0.764179</td>\n",
       "      <td>0.785276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.761696</td>\n",
       "      <td>0.766810</td>\n",
       "      <td>0.834891</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.799387</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.793313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.789790</td>\n",
       "      <td>0.796970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.802343</td>\n",
       "      <td>0.798834</td>\n",
       "      <td>0.805882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.836257</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.834320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.773994</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.778816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.540264</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.833089</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.813084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.831625</td>\n",
       "      <td>0.819466</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.800613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.830161</td>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.843949</td>\n",
       "      <td>0.798193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.812592</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.745399</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.786888</td>\n",
       "      <td>0.731628</td>\n",
       "      <td>0.732497</td>\n",
       "      <td>0.757733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.818713  0.815476  0.817910   0.813056\n",
       "1     0.820175  0.809302  0.825949   0.793313\n",
       "2     0.837719  0.832073  0.820896   0.843558\n",
       "3     0.836257  0.833333  0.802292   0.866873\n",
       "4     0.846491  0.836703  0.822630   0.851266\n",
       "5     0.839181  0.830247  0.832817   0.827692\n",
       "6     0.814327  0.812960  0.838906   0.788571\n",
       "7     0.782164  0.774584  0.764179   0.785276\n",
       "8     0.761696  0.766810  0.834891   0.708995\n",
       "9     0.808480  0.799387  0.805556   0.793313\n",
       "10    0.500000  0.000000  0.000000   0.000000\n",
       "11    0.799708  0.793363  0.789790   0.796970\n",
       "12    0.802632  0.802343  0.798834   0.805882\n",
       "13    0.836257  0.834320  0.834320   0.834320\n",
       "14    0.786237  0.773994  0.769231   0.778816\n",
       "15    0.540264  0.065476  0.034591   0.611111\n",
       "16    0.833089  0.820755  0.828571   0.813084\n",
       "17    0.831625  0.819466  0.839228   0.800613\n",
       "18    0.830161  0.820433  0.843949   0.798193\n",
       "19    0.812592  0.791531  0.745399   0.843750\n",
       "mean  0.786888  0.731628  0.732497   0.757733"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_high_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_mix.to_excel('df_high_mix.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qo4MA2A6_NQi"
   },
   "source": [
    "### 3.4 Education Mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1 Mixed on low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7733918128654971\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.7792397660818714\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.8026315789473685\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8128654970760234\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8084795321637427\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7850877192982456\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.7646198830409356\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.8172514619883041\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.7953216374269005\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.8070175438596491\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.8114035087719298\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.783625730994152\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.7997076023391813\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.7894736842105263\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.8096632503660323\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.7979502196193266\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.808199121522694\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.7935578330893118\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.7862371888726208\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.7657393850658858\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edulow_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_mixed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_mix_low = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_mix_low.loc['mean'] = df_mix_low.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.773392</td>\n",
       "      <td>0.769688</td>\n",
       "      <td>0.814465</td>\n",
       "      <td>0.729577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.779240</td>\n",
       "      <td>0.778917</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.732782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.789392</td>\n",
       "      <td>0.834983</td>\n",
       "      <td>0.748521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.800623</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.785933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.799387</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.793313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.763473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.764620</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.758514</td>\n",
       "      <td>0.746951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.817251</td>\n",
       "      <td>0.805599</td>\n",
       "      <td>0.827476</td>\n",
       "      <td>0.784848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.795322</td>\n",
       "      <td>0.779874</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.751515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.797546</td>\n",
       "      <td>0.817610</td>\n",
       "      <td>0.778443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.794913</td>\n",
       "      <td>0.830565</td>\n",
       "      <td>0.762195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.771605</td>\n",
       "      <td>0.778816</td>\n",
       "      <td>0.764526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.780800</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>0.739394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>0.781538</td>\n",
       "      <td>0.776758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.809663</td>\n",
       "      <td>0.799383</td>\n",
       "      <td>0.811912</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.797950</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.800633</td>\n",
       "      <td>0.771341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.808199</td>\n",
       "      <td>0.794349</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.768997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.772213</td>\n",
       "      <td>0.818493</td>\n",
       "      <td>0.730887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.786237</td>\n",
       "      <td>0.778788</td>\n",
       "      <td>0.774096</td>\n",
       "      <td>0.783537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.765739</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.775578</td>\n",
       "      <td>0.718654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.794573</td>\n",
       "      <td>0.782645</td>\n",
       "      <td>0.806292</td>\n",
       "      <td>0.760944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.773392  0.769688  0.814465   0.729577\n",
       "1     0.779240  0.778917  0.831250   0.732782\n",
       "2     0.802632  0.789392  0.834983   0.748521\n",
       "3     0.812865  0.800623  0.815873   0.785933\n",
       "4     0.808480  0.799387  0.805556   0.793313\n",
       "5     0.785088  0.776256  0.789474   0.763473\n",
       "6     0.764620  0.752688  0.758514   0.746951\n",
       "7     0.817251  0.805599  0.827476   0.784848\n",
       "8     0.795322  0.779874  0.810458   0.751515\n",
       "9     0.807018  0.797546  0.817610   0.778443\n",
       "10    0.811404  0.794913  0.830565   0.762195\n",
       "11    0.783626  0.771605  0.778816   0.764526\n",
       "12    0.799708  0.780800  0.827119   0.739394\n",
       "13    0.789474  0.779141  0.781538   0.776758\n",
       "14    0.809663  0.799383  0.811912   0.787234\n",
       "15    0.797950  0.785714  0.800633   0.771341\n",
       "16    0.808199  0.794349  0.821429   0.768997\n",
       "17    0.793558  0.772213  0.818493   0.730887\n",
       "18    0.786237  0.778788  0.774096   0.783537\n",
       "19    0.765739  0.746032  0.775578   0.718654\n",
       "mean  0.794573  0.782645  0.806292   0.760944"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_low.to_excel('df_high_low.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Mixed on medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.8011695906432749\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.8084795321637427\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.8084795321637427\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8084795321637427\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8347953216374269\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.8245614035087719\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8084795321637427\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.8318713450292398\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.8260233918128655\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.8099415204678363\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.8391812865497076\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.8099415204678363\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.8128654970760234\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.8216374269005848\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.8052708638360175\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.8257686676427526\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.83601756954612\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8330893118594437\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.8111273792093704\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.8155197657393851\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_edumed_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_mixed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_mix_med = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_mix_med.loc['mean'] = df_mix_med.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.803468</td>\n",
       "      <td>0.759563</td>\n",
       "      <td>0.852761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.807069</td>\n",
       "      <td>0.782857</td>\n",
       "      <td>0.832827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.803008</td>\n",
       "      <td>0.789941</td>\n",
       "      <td>0.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.805926</td>\n",
       "      <td>0.783862</td>\n",
       "      <td>0.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.834795</td>\n",
       "      <td>0.831091</td>\n",
       "      <td>0.815249</td>\n",
       "      <td>0.847561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.825581</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.865854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.808480</td>\n",
       "      <td>0.810967</td>\n",
       "      <td>0.767760</td>\n",
       "      <td>0.859327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.831871</td>\n",
       "      <td>0.825493</td>\n",
       "      <td>0.824242</td>\n",
       "      <td>0.826748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.826023</td>\n",
       "      <td>0.823704</td>\n",
       "      <td>0.801153</td>\n",
       "      <td>0.847561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.809942</td>\n",
       "      <td>0.804805</td>\n",
       "      <td>0.795252</td>\n",
       "      <td>0.814590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.839181</td>\n",
       "      <td>0.834835</td>\n",
       "      <td>0.822485</td>\n",
       "      <td>0.847561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.809942</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.783862</td>\n",
       "      <td>0.831804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.812865</td>\n",
       "      <td>0.805471</td>\n",
       "      <td>0.807927</td>\n",
       "      <td>0.803030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.821637</td>\n",
       "      <td>0.817910</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.805271</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.825769</td>\n",
       "      <td>0.818321</td>\n",
       "      <td>0.819572</td>\n",
       "      <td>0.817073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.836018</td>\n",
       "      <td>0.834320</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.859756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.833089</td>\n",
       "      <td>0.828313</td>\n",
       "      <td>0.813609</td>\n",
       "      <td>0.843558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.811127</td>\n",
       "      <td>0.806597</td>\n",
       "      <td>0.795858</td>\n",
       "      <td>0.817629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.815520</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.779944</td>\n",
       "      <td>0.856269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.818635</td>\n",
       "      <td>0.815516</td>\n",
       "      <td>0.796760</td>\n",
       "      <td>0.835678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.801170  0.803468  0.759563   0.852761\n",
       "1     0.808480  0.807069  0.782857   0.832827\n",
       "2     0.808480  0.803008  0.789941   0.816514\n",
       "3     0.808480  0.805926  0.783862   0.829268\n",
       "4     0.834795  0.831091  0.815249   0.847561\n",
       "5     0.824561  0.825581  0.788889   0.865854\n",
       "6     0.808480  0.810967  0.767760   0.859327\n",
       "7     0.831871  0.825493  0.824242   0.826748\n",
       "8     0.826023  0.823704  0.801153   0.847561\n",
       "9     0.809942  0.804805  0.795252   0.814590\n",
       "10    0.839181  0.834835  0.822485   0.847561\n",
       "11    0.809942  0.807122  0.783862   0.831804\n",
       "12    0.812865  0.805471  0.807927   0.803030\n",
       "13    0.821637  0.817910  0.801170   0.835366\n",
       "14    0.805271  0.800000  0.791667   0.808511\n",
       "15    0.825769  0.818321  0.819572   0.817073\n",
       "16    0.836018  0.834320  0.810345   0.859756\n",
       "17    0.833089  0.828313  0.813609   0.843558\n",
       "18    0.811127  0.806597  0.795858   0.817629\n",
       "19    0.815520  0.816327  0.779944   0.856269\n",
       "mean  0.818635  0.815516  0.796760   0.835678"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_med.to_excel('df_mix_med.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Mixed on high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.7982456140350878\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 0.8187134502923976\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.8114035087719298\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.8157894736842105\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.8114035087719298\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.7967836257309941\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.8157894736842105\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 0.8494152046783626\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.8260233918128655\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.8245614035087719\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.8406432748538012\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.8289473684210527\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.804093567251462\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 0.8333333333333334\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.7994143484626647\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.8404099560761347\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.8448023426061494\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 0.8023426061493412\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.8243045387994143\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.8257686676427526\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_eduhigh_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_mixed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_mix_high = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_mix_high.loc['mean'] = df_mix_high.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.795252</td>\n",
       "      <td>0.772334</td>\n",
       "      <td>0.819572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818713</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>0.786585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.801233</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>0.795107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.806154</td>\n",
       "      <td>0.813665</td>\n",
       "      <td>0.798780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.803053</td>\n",
       "      <td>0.799392</td>\n",
       "      <td>0.806748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.796784</td>\n",
       "      <td>0.782473</td>\n",
       "      <td>0.801282</td>\n",
       "      <td>0.764526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.810241</td>\n",
       "      <td>0.798220</td>\n",
       "      <td>0.822630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.849415</td>\n",
       "      <td>0.846954</td>\n",
       "      <td>0.830904</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.826023</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.820988</td>\n",
       "      <td>0.813456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.815951</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.840643</td>\n",
       "      <td>0.834094</td>\n",
       "      <td>0.830303</td>\n",
       "      <td>0.837920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.819165</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.810398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.804094</td>\n",
       "      <td>0.792570</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>0.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.819820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.799414</td>\n",
       "      <td>0.788906</td>\n",
       "      <td>0.797508</td>\n",
       "      <td>0.780488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.840410</td>\n",
       "      <td>0.834094</td>\n",
       "      <td>0.832827</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.844802</td>\n",
       "      <td>0.840361</td>\n",
       "      <td>0.827893</td>\n",
       "      <td>0.853211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.802343</td>\n",
       "      <td>0.788069</td>\n",
       "      <td>0.809677</td>\n",
       "      <td>0.767584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.824305</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.798165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.825769</td>\n",
       "      <td>0.816074</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.807339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.820609</td>\n",
       "      <td>0.811923</td>\n",
       "      <td>0.815724</td>\n",
       "      <td>0.808517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.798246  0.795252  0.772334   0.819572\n",
       "1     0.818713  0.806250  0.826923   0.786585\n",
       "2     0.811404  0.801233  0.807453   0.795107\n",
       "3     0.815789  0.806154  0.813665   0.798780\n",
       "4     0.811404  0.803053  0.799392   0.806748\n",
       "5     0.796784  0.782473  0.801282   0.764526\n",
       "6     0.815789  0.810241  0.798220   0.822630\n",
       "7     0.849415  0.846954  0.830904   0.863636\n",
       "8     0.826023  0.817204  0.820988   0.813456\n",
       "9     0.824561  0.815951  0.823529   0.808511\n",
       "10    0.840643  0.834094  0.830303   0.837920\n",
       "11    0.828947  0.819165  0.828125   0.810398\n",
       "12    0.804094  0.792570  0.805031   0.780488\n",
       "13    0.833333  0.827273  0.834862   0.819820\n",
       "14    0.799414  0.788906  0.797508   0.780488\n",
       "15    0.840410  0.834094  0.832827   0.835366\n",
       "16    0.844802  0.840361  0.827893   0.853211\n",
       "17    0.802343  0.788069  0.809677   0.767584\n",
       "18    0.824305  0.813084  0.828571   0.798165\n",
       "19    0.825769  0.816074  0.825000   0.807339\n",
       "mean  0.820609  0.811923  0.815724   0.808517"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_high.to_excel('df_mix_high.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.4. Mixed on mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Fold 1/20\n",
      "Accuracy for Fold 1: 0.9941520467836257\n",
      "Training Fold 2/20\n",
      "Accuracy for Fold 2: 1.0\n",
      "Training Fold 3/20\n",
      "Accuracy for Fold 3: 0.9985380116959064\n",
      "Training Fold 4/20\n",
      "Accuracy for Fold 4: 0.9985380116959064\n",
      "Training Fold 5/20\n",
      "Accuracy for Fold 5: 0.9985380116959064\n",
      "Training Fold 6/20\n",
      "Accuracy for Fold 6: 0.9985380116959064\n",
      "Training Fold 7/20\n",
      "Accuracy for Fold 7: 0.9956140350877193\n",
      "Training Fold 8/20\n",
      "Accuracy for Fold 8: 1.0\n",
      "Training Fold 9/20\n",
      "Accuracy for Fold 9: 0.9985380116959064\n",
      "Training Fold 10/20\n",
      "Accuracy for Fold 10: 0.9941520467836257\n",
      "Training Fold 11/20\n",
      "Accuracy for Fold 11: 0.9985380116959064\n",
      "Training Fold 12/20\n",
      "Accuracy for Fold 12: 0.9897660818713451\n",
      "Training Fold 13/20\n",
      "Accuracy for Fold 13: 0.9970760233918129\n",
      "Training Fold 14/20\n",
      "Accuracy for Fold 14: 1.0\n",
      "Training Fold 15/20\n",
      "Accuracy for Fold 15: 0.9941434846266471\n",
      "Training Fold 16/20\n",
      "Accuracy for Fold 16: 0.9970717423133236\n",
      "Training Fold 17/20\n",
      "Accuracy for Fold 17: 0.9956076134699854\n",
      "Training Fold 18/20\n",
      "Accuracy for Fold 18: 1.0\n",
      "Training Fold 19/20\n",
      "Accuracy for Fold 19: 0.9970717423133236\n",
      "Training Fold 20/20\n",
      "Accuracy for Fold 20: 0.9985358711566618\n"
     ]
    }
   ],
   "source": [
    "# Convert dataframe to dataset\n",
    "dataset_train = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #High in train set\n",
    "dataset_test = TextDataset(df['c_text'].tolist(), df['bereichernd_mixed_median'].tolist()) #Mixed in test set\n",
    "\n",
    "\n",
    "# Define k-fold cross-validation\n",
    "k_folds = 20\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store accuracies for each fold\n",
    "fold_accuracies = []\n",
    "fold_f1s = []\n",
    "fold_recalls = []\n",
    "fold_precisions = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(df['c_text'], df['bereichernd_mixed_median'])):\n",
    "    print(f\"Training Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    # Split dataset into train and validation sets for the current fold\n",
    "    train_dataset = torch.utils.data.Subset(dataset_train, train_indices)\n",
    "    val_dataset = torch.utils.data.Subset(dataset_test, val_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "            val_predictions.extend(predicted_labels.tolist())\n",
    "            val_labels.extend(labels.tolist())\n",
    "\n",
    "    fold_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    fold_accuracies.append(fold_accuracy)\n",
    "    print(f\"Accuracy for Fold {fold+1}: {fold_accuracy}\")\n",
    "\n",
    "\n",
    "    fold_f1 = f1_score(val_labels, val_predictions)\n",
    "    fold_f1s.append(fold_f1)\n",
    "\n",
    "    fold_recall = recall_score(val_labels, val_predictions)\n",
    "    fold_recalls.append(fold_recall)\n",
    "\n",
    "    fold_precision = precision_score(val_labels, val_predictions)\n",
    "    fold_precisions.append(fold_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new df\n",
    "df_mix_mix = pd.DataFrame({'accuracy':fold_accuracies,\n",
    "                                        'f1':fold_f1s,\n",
    "                                        'recall':fold_recalls,\n",
    "                                        'precision':fold_precisions\n",
    "                                        })\n",
    "#Add row with mean\n",
    "df_mix_mix.loc['mean'] = df_mix_mix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995614</td>\n",
       "      <td>0.995420</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.996942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.994152</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.990854</td>\n",
       "      <td>0.996933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.989766</td>\n",
       "      <td>0.989247</td>\n",
       "      <td>0.981707</td>\n",
       "      <td>0.996904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.997076</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.996951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.994143</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>0.990854</td>\n",
       "      <td>0.996933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.996942</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.995608</td>\n",
       "      <td>0.995420</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>0.996942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.997072</td>\n",
       "      <td>0.996942</td>\n",
       "      <td>0.993902</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.998536</td>\n",
       "      <td>0.998473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.997221</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>0.995732</td>\n",
       "      <td>0.998472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accuracy        f1    recall  precision\n",
       "0     0.994152  0.993865  0.987805   1.000000\n",
       "1     1.000000  1.000000  1.000000   1.000000\n",
       "2     0.998538  0.998473  0.996951   1.000000\n",
       "3     0.998538  0.998473  0.996951   1.000000\n",
       "4     0.998538  0.998478  1.000000   0.996960\n",
       "5     0.998538  0.998478  1.000000   0.996960\n",
       "6     0.995614  0.995420  0.993902   0.996942\n",
       "7     1.000000  1.000000  1.000000   1.000000\n",
       "8     0.998538  0.998478  1.000000   0.996960\n",
       "9     0.994152  0.993884  0.990854   0.996933\n",
       "10    0.998538  0.998473  0.996951   1.000000\n",
       "11    0.989766  0.989247  0.981707   0.996904\n",
       "12    0.997076  0.996951  0.996951   0.996951\n",
       "13    1.000000  1.000000  1.000000   1.000000\n",
       "14    0.994143  0.993884  0.990854   0.996933\n",
       "15    0.997072  0.996942  0.993902   1.000000\n",
       "16    0.995608  0.995420  0.993902   0.996942\n",
       "17    1.000000  1.000000  1.000000   1.000000\n",
       "18    0.997072  0.996942  0.993902   1.000000\n",
       "19    0.998536  0.998473  1.000000   0.996951\n",
       "mean  0.997221  0.997094  0.995732   0.998472"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mix_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mix_mix.to_excel('df_mix_mix.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOuwkWM6vYxNI7pdWPDupba",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1iY1CcLgHzTzH-KbBGCG1lXU1Xuf0BxNo",
     "timestamp": 1729085756682
    },
    {
     "file_id": "19hZQwF1SgpAtZ7hlRc5S4kvT__33ce6W",
     "timestamp": 1717418515484
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "002be2421cee49b9bc5d4fb12e4a42e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0196862b0e8d4d04b6bc8077247c98c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "046f6e0480ac4e46b551021ee5b904e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "04f95987f8d84afbb0e344a6870cac7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "066e549739d341818d9ccc76a264ae30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bda31ca95fa14876b981bc3cc2874cc2",
      "placeholder": "​",
      "style": "IPY_MODEL_dee3d7926b9e4c71bce69d233f4f2f8e",
      "value": " 59.0/59.0 [00:00&lt;00:00, 4.15kB/s]"
     }
    },
    "1cf017a6706440d79ba58c3fa5f26e38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2196ee353dd84ffc818d1c8c197e6058",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4f1e3641613449a3b2b0418038326bfd",
      "value": 433
     }
    },
    "2196ee353dd84ffc818d1c8c197e6058": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25605175e36945a491de2aecdd653c46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "311e839405b14da0a5e1207da92400f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ad1774bccad4a8ea57bb78686b40957",
       "IPY_MODEL_bd215e0ca74847118ba8a7c00429cac2",
       "IPY_MODEL_066e549739d341818d9ccc76a264ae30"
      ],
      "layout": "IPY_MODEL_86a8a6037dc744e2adb3d2e2deb5946b"
     }
    },
    "4796ddabaefc44f281846d34f0a22f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c4a6ceb3c4234b01b04b1d32fb57afcd",
       "IPY_MODEL_d1977360515f447ab2ba2fa6dcff4da6",
       "IPY_MODEL_7e8e9ff2ce9b441eba07e0c5d5612660"
      ],
      "layout": "IPY_MODEL_b897a71e5e264c8d9036d4d5361ae132"
     }
    },
    "4d9522d74317477dae9dba9675b4eab3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1e3641613449a3b2b0418038326bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "574f7feb86d5464c98777878924aec07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad25b59e1e747f2a155cd1585888fe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69d1b191bdbe47adbe37a0f3e7c68dc4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ad1774bccad4a8ea57bb78686b40957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d1b191bdbe47adbe37a0f3e7c68dc4",
      "placeholder": "​",
      "style": "IPY_MODEL_25605175e36945a491de2aecdd653c46",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "72e9a1b0af3f4414981f9606c26ba7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72eaab231ff94c25b5568ca8640ca0d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bfe52c53bf8458fa95d96632b6da289": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6541e0304e24b34bdce0a4d6f2b8b38",
      "placeholder": "​",
      "style": "IPY_MODEL_046f6e0480ac4e46b551021ee5b904e3",
      "value": " 433/433 [00:00&lt;00:00, 26.1kB/s]"
     }
    },
    "7e8e9ff2ce9b441eba07e0c5d5612660": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9455b1c891439b9666419c7b7e3e1b",
      "placeholder": "​",
      "style": "IPY_MODEL_eabcf87c37f0422a865b7f92ea00a69f",
      "value": " 247k/247k [00:00&lt;00:00, 1.77MB/s]"
     }
    },
    "81be217159c94fa4ad80131da2cbf843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d896ea7dcfaa4c9494230c6646268aed",
       "IPY_MODEL_1cf017a6706440d79ba58c3fa5f26e38",
       "IPY_MODEL_7bfe52c53bf8458fa95d96632b6da289"
      ],
      "layout": "IPY_MODEL_002be2421cee49b9bc5d4fb12e4a42e0"
     }
    },
    "86a8a6037dc744e2adb3d2e2deb5946b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9455b1c891439b9666419c7b7e3e1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6541e0304e24b34bdce0a4d6f2b8b38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b897a71e5e264c8d9036d4d5361ae132": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd215e0ca74847118ba8a7c00429cac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0196862b0e8d4d04b6bc8077247c98c6",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04f95987f8d84afbb0e344a6870cac7b",
      "value": 59
     }
    },
    "bda31ca95fa14876b981bc3cc2874cc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1c9fd4c308c475195449c41201fb2d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4a6ceb3c4234b01b04b1d32fb57afcd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d9522d74317477dae9dba9675b4eab3",
      "placeholder": "​",
      "style": "IPY_MODEL_c1c9fd4c308c475195449c41201fb2d8",
      "value": "vocab.txt: 100%"
     }
    },
    "d1977360515f447ab2ba2fa6dcff4da6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_574f7feb86d5464c98777878924aec07",
      "max": 247333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72e9a1b0af3f4414981f9606c26ba7ce",
      "value": 247333
     }
    },
    "d896ea7dcfaa4c9494230c6646268aed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72eaab231ff94c25b5568ca8640ca0d0",
      "placeholder": "​",
      "style": "IPY_MODEL_5ad25b59e1e747f2a155cd1585888fe1",
      "value": "config.json: 100%"
     }
    },
    "dee3d7926b9e4c71bce69d233f4f2f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eabcf87c37f0422a865b7f92ea00a69f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
