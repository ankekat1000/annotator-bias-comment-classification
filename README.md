### Analysis source-code to our study:
## Investigating annotator bias in comment quality and incivility classification by formal education

Machine learning models used in algorithmic content moderation in online debates play an increasingly important role in detecting norm-violating, uncivil (e.g., toxic, hateful, or abusive) comments. Trained on human decisions, these models risk reproducing annotator bias, particularly when the training data reflects a limited range of perspectives that systematically vary across social backgrounds. This study investigates the potential impact of annotatorsâ€™ formal education on the classification of high-quality (deliberative) and uncivil user contributions in online discussions. Using a dataset of 13,677 German user comments annotated by crowd workers with low, medium, and high formal education, we investigate potential divergences in classification outcomes as well as statistical associations between language features and the annotations of the educationally diverse groups. Our results indicate that classifiers for high-quality and uncivil comments yield significantly different results when trained on data labeled by annotators with varying educational backgrounds. In addition, some communication features linked to deliberative quality (e.g., solution proposals, additional knowledge) and incivility (e.g., vulgarity, accusation of lying) are more strongly associated with annotations by crowd annotators with medium and high formal education. We argue that such group-specific differences should be considered when developing machine learning models in both practice and research to reflect a more inclusive understanding of comment quality and incivility.


## Method
tbc



### Please read and cite:
Wilms et al. (2025):

```
Wilms et al. (2025):
```



### Copyright and license

Code released under the [CC BY-NC 4.0 License](https://creativecommons.org/licenses/by-nc/4.0/deed.en).

Enjoy ðŸ’ž
